[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "ImgLib2",
    "section": "",
    "text": "ImgLib2 is a general-purpose, multidimensional image and data processing library.\nIt provides a unified API to work with discrete and continuous n-dimensional data. This API is interface driven and therefore extensible at will.\nImgLib2 includes implementations of standard numeric and non-numeric data types (8-bit unsigned integer, 32-bit floating point, …) as well as a number of less typical data types (complex 64-bit floating point, 64-bit ARGB, base pairs, …). Data values can be accessed directly or through on-the-fly converters or multi-variate functions.\nFor discrete data (images, n-dimensional arrays), ImgLib2 implements a variety of memory layouts, data generation, loading, and caching strategies, including data linearized into single primitive arrays, series of arrays, n-dimensional arrays of arrays (“cells”), stored in memory, generated or loaded from disk on demand, and cached in memory or on disk. Coordinates and values can be accessed directly or through on-the-fly views that invert or permute axes, generate hyperslices or stack slices top higher dimensional datasets, collapse dimensions into vectors\nFor continuous data (functions, n-dimensional interpolants), ImgLib2 implements a variety of interpolators, geometric transformations, and generator functions. Coordinates and values can be accessed directly or transformed on-the-fly.\nNeed a quick start? Install OpenJDK and maven:\nsudo apt install openjdk-16-jdk maven\nThen check out BigDataViewer vistools:\ngit clone https://github.com/bigdataviewer/bigdataviewer-vistools.git\nThen start JShell in the BigDataViewer vistools project directory:\ncd bigdataviewer-vistools\nmvn compile com.github.johnpoth:jshell-maven-plugin:1.3:run\nThen try out this code snippet:\nimport bdv.util.*;\nimport net.imglib2.position.FunctionRealRandomAccessible;\nimport net.imglib2.type.numeric.integer.IntType;\nimport net.imglib2.util.Intervals;\n\nBdvFunctions.show(\n  new FunctionRealRandomAccessible&lt;IntType&gt;(\n    2,\n    (x, y) -&gt; {\n      int i = 0;\n      double v = 0,\n        c = x.getDoublePosition(0),\n        d = x.getDoublePosition(1);\n      for (; i &lt; 64 && v &lt; 4096; ++i) {\n        final double e = c * c - d * d;\n        d = 2 * c * d;\n        c = e + 0.2;\n        d += 0.6;\n        v = Math.sqrt(c * c + d * d);\n        ++i;\n      }\n      y.set(i);\n    },\n    IntType::new),\n  Intervals.createMinMax(-1, -1, 1, 1),\n  \"\",\n  BdvOptions.options().is2D()).setDisplayRange(0, 64);"
  },
  {
    "objectID": "posts/2022-06-05-setup-ijava-jupyter-kernel.html",
    "href": "posts/2022-06-05-setup-ijava-jupyter-kernel.html",
    "title": "Setup the IJava jupyter kernel",
    "section": "",
    "text": "In this blog, we will show code snippets and examples to make the best use of ImgLib2, BigDataViewer, and friends. ImgLib2 is written to be fast and we will run code that needs to be compiled, so we cannot use any of the various interpreted scripting languages like Python, Groovy, or Javascript. Instead, we will use the JShell tool that you can use directly in a terminal or through Spencer Park’s IJava jupyter kernel. You can also follow these tutorials in your own Java project and use your preferred IDE, but Jupyter notebooks are a great teaching tool. Since jupyter is written in Python and most popular with the Python community, let’s follow their ways and first thing create a virtual environment with conda. The lack of version controlled dependency management for Python projects makes it necessary that practically every project must run in a container or virtual environment because the dependencies of different projects almost inevitably collide. Conda is the most popular of several attempts to address this situation. Conda cannot currently be installed from the default Ubuntu repositories, so much about that, but the installation instructions are tolerable, there is a PPA. Now let’s create an environment for jupyter:\nconda create -n jshell-jupyter python=3\nconda init bash\nconda activate jshell-jupyter\nconda install jupyter\nYou will also need a modern Java and Maven on your system, so if you have not yet done so, install it:\nsudo apt install openjdk-17-jdk maven\nThe original IJava kernel currently does not build with Java 17 or 18, so we use Philipp Hanslovsky’s fork and build and install both the kernel installer and the IJava Jupyter kernel:\ngit clone https://github.com/hanslovsky/Jupyter-kernel-installer-gradle.git\ncd Jupyter-kernel-installer-gradle/\ngit checkout try-upgrade-gradle\n./gradlew publishToMavenLocal\n\ncd ..\ngit clone https://github.com/hanslovsky/IJava.git\ncd IJava/\ngit checkout hanslovsky/gradle-7.4.2\n./gradlew installKernel\nNow check if the kernel is installed, this should print something like this\njupyter kernelspec list\n\nAvailable kernels:\n  java       /home/saalfeld/.local/share/jupyter/kernels/java\n  python3    /home/saalfeld/anaconda3/envs/jshell-jupyter/share/jupyter/kernels/python3\nYou can now start the jupyter notebook server\njupyter notebook --kernel=java\nAnd experiment with the examples. Spencer Park’s IJava jupyter kernel makes it very easy to include dependencies. You can include the relevant snippets from a Maven POM into a tagged code block, e.g.\n%%loadFromPOM\n&lt;repository&gt;\n    &lt;id&gt;scijava.public&lt;/id&gt;\n    &lt;url&gt;https://maven.scijava.org/content/groups/public&lt;/url&gt;\n&lt;/repository&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;sc.fiji&lt;/groupId&gt;\n    &lt;artifactId&gt;bigdataviewer-vistools&lt;/artifactId&gt;\n    &lt;version&gt;1.0.0-beta-29&lt;/version&gt;\n&lt;/dependency&gt;\nIf you prefer to run JShell directly, you can pull in the dependencies from a complete Maven POM with John Pooth’s Maven Jshell plugin\nmvn compile com.github.johnpoth:jshell-maven-plugin:1.3:run\nHappy JShelling!\nP.S.:\nThe original IJava kernel currently does not build with Java 17 or 18, so if you prefer this over the above fork, or if you do not care about the latest greatest language features in Java 17, then the easiest at this time is to use OpenJDK-11. If you don’t have it yet, install it via conda:\nconda install openjdk\nconda install -c conda-forge maven\nHowever, this may take a day of solving environments, so you can also install it globally:\nsudo apt install openjdk-11-jdk maven\nIf you have other versions installed, you can switch between them with the alternatives tool:\nsudo update-alternatives --config java\nsudo update-alternatives --config javac\nNow check out the original IJava and build and install the kernel IJava Jupyter kernel following the installation instructions or:\ngit clone https://github.com/SpencerPark/IJava.git\ncd IJava/\n./gradlew installKernel\njupyter kernelspec list\nDone."
  },
  {
    "objectID": "posts/2024-02-14-displacementFields/2024-02-14-displacementFields.html",
    "href": "posts/2024-02-14-displacementFields/2024-02-14-displacementFields.html",
    "title": "Position and displacement field transforms",
    "section": "",
    "text": "This post shows how to create and apply non-linear transformations with imglib2, specifically using DisplacementFieldTransforms and PositionFieldTransforms.\nThe last example of this post will show how to use a PositionFieldTransform to create a 2D image from a 1D signal by a transformation of coordinates.\n\n\n\n\n\n\n\nA 2D image created after transformation\nof this 1D function\n\n\n\n\n\n\n\n\n\nThe code folded below sets up dependencies, imports classes, and makes it convenient to show image output as shown in this post.\n\n\nCode\n%mavenRepo scijava.public https://maven.scijava.org/content/groups/public\n\n%maven net.imagej:ij:1.54f\n%maven org.scijava:scijava-common:2.97.0\n%maven net.imglib2:imglib2:6.2.0\n%maven net.imglib2:imglib2-ij:2.0.1\n%maven net.imglib2:imglib2-realtransform:4.0.1\n%maven org.knowm.xchart:xchart:3.5.4\n    \nimport java.util.function.*;\nimport java.util.stream.*;\nimport java.awt.image.BufferedImage;\n\nimport io.github.spencerpark.jupyter.kernel.display.common.*;\nimport io.github.spencerpark.jupyter.kernel.display.mime.*;\n\nimport ij.*;\nimport net.imglib2.*;\nimport net.imglib2.view.*;\nimport net.imglib2.util.*;\nimport net.imglib2.realtransform.*;\nimport net.imglib2.position.*;\nimport net.imglib2.type.numeric.*;\nimport net.imglib2.type.numeric.real.*;\nimport net.imglib2.type.numeric.integer.*;\nimport net.imglib2.interpolation.randomaccess.*;\nimport net.imglib2.img.display.imagej.*;\nimport net.imglib2.img.imageplus.ImagePlusImgs;\nimport net.imglib2.img.array.ArrayImgs;\n\npublic static &lt;T extends NumericType&lt;T&gt;&gt; BufferedImage toBuffferedImage( RandomAccessibleInterval rai ) {\n    return ImageJFunctions.wrap( (RandomAccessibleInterval&lt;T&gt;)rai, \"\").getBufferedImage();\n}\n\ngetKernelInstance().getRenderer().createRegistration(RandomAccessibleInterval.class)\n        .preferring(MIMEType.IMAGE_PNG)\n        .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n        .register((rai, context) -&gt; Image.renderImage(toBuffferedImage(rai),context));\n\nvar printWriter = new PrintWriter(System.out,true);\nchar rarrow = '\\u2192';\npublic static void printTformPts( RealPoint x, RealPoint y ) {\n    printWriter.println( String.format(\"%s %s %s\", x, rarrow, y));\n};\n\n\n\nDisplacement fields\nA displacement field is the most common way to represent and store non-linear transformations. Imagine an image where a vector is stored at every position \\(\\mathbf{x}\\). That vector describes how much and in what direction the position \\(\\mathbf{x}\\) should be translated, or displaced.\n\\[\n\\begin{align}\n\\mathbf{x} &: \\text{a position } \\\\\n\\mathbf{v}( \\mathbf{x} ) &: \\text{the vector at position } \\mathbf{x}\\\\\n\\mathbf{x} + \\mathbf{v}( \\mathbf{x} ) &: \\text{the output of the transformation}\n\\end{align}\n\\]\nFor example, let’s consider an example vector field with the vector \\([50, -25]\\) at every position. This will be equivalent to a simple global translation and is not the recommended way to represent a translation, but will be instructive thanks to its simplicity.\nA FunctionRealRandomAccessible is one way to make a image containing a constant value (ConstantUtils is another way). This image can be passed directly to imglib2’s DisplacementFieldTransform.\n\n\nCode\nvar displacementVector = new double[]{50, -25};        // the constant vector\n\n// an image that takes the value of displacementVector everywhere\nvar constantVector = new FunctionRealRandomAccessible&lt;&gt;( 2,\n    (x, v) -&gt; { v.setPosition(displacementVector ); }, // set the vector \n    () -&gt; { return DoubleType.createVector(2); });     // make a 2d vector\n\n// a constant displacement field\nvar dfieldConstant = new DisplacementFieldTransform(constantVector);\n\n\nApplying the transformation to any point translates that point by the same amount \\([50, -25]\\) , as expected:\n\n\nCode\n// two ways of initializing a point (0.0, 0.0)\nvar x = new RealPoint(0.0, 0.0); // give the coordinates as arguments\nvar y = new RealPoint(2);        // give the number of dimensions as an argument\n\n// transform x, store the result in y\ndfieldConstant.apply(x, y);\n // [0, 0] is transformed to [50, -25]\nprintTformPts(x, y);\n\n// [-50, 25] is transformed to [0, 0]\nx = new RealPoint(-50, 25);\ndfieldConstant.apply(x, y);\nprintTformPts(x, y);\n\n// [pi, 100k] is transformed to [pi + 50, 100k - 25]\nx = new RealPoint( Math.PI, 100000 );\ndfieldConstant.apply(x, y);\nprintTformPts(x, y);\n\n\n(0.0,0.0) → (50.0,-25.0)\n(-50.0,25.0) → (0.0,0.0)\n(3.141592653589793,100000.0) → (53.1415926535898,99975.0)\n\n\nLet’s make a slightly more interesting displacement field with four vectors - one at each corner. Our image will be:\n----------------\n|[1, 1]  [2, 2]|\n|[3, 3]  [4, 4]|\n----------------\ni.e. the vector at position (0,1) is \\([3,3]\\).\nOur data needs to be 3D, where the first dimension holds the two vector components, and the other two hold the spatial dimensions. We can use an ArrayImg to store these data.\n\n\nCode\nvar dfieldData = ArrayImgs.doubles( \n    new double[]{1, 1, 2, 2, 3, 3, 4, 4}, // the data\n    2, 2, 2 );  // the dimensions\n\n// the displacement field\nvar dfieldCorners = new DisplacementFieldTransform(dfieldData);\n\n\nFor example, we expect the transform to take the point \\([0,1]\\) to \\([3,4] = [0,1] + [3,3]\\), and that is indeed what we see:\n\n\nCode\n// [0,0] is transformed to [1,1] = [0,0] + [1,1]\nvar x = new RealPoint(0.0, 0.0);\nvar y = new RealPoint(2);\ndfieldCorners.apply(x, y);\nprintTformPts(x, y);\n\n// [1,0] is transformed to [3,2] = [1,0] + [2,2]\nvar x = new RealPoint(1.0, 0.0);\ndfieldCorners.apply(x, y);\nprintTformPts(x, y);\n\n// [0,1] is transformed to [3,4] = [0,1] + [3,3]\nvar x = new RealPoint(0.0, 1.0);\ndfieldCorners.apply(x, y);\nprintTformPts(x, y);\n\n// [1,1] is transformed to [5,5] = [1,1] + [4,4]\nvar x = new RealPoint(1.0, 1.0);\ndfieldCorners.apply(x, y);\nprintTformPts(x, y);\n\n\n(0.0,0.0) → (1.0,1.0)\n(1.0,0.0) → (3.0,2.0)\n(0.0,1.0) → (3.0,4.0)\n(1.0,1.0) → (5.0,5.0)\n\n\nWhat happens if we try to apply the transformation “in between” the discrete values of the array, or out-of-bounds of the array?\n\n\nCode\n// [0.5, 0.5] is transformed to [3.0, 3.0]\nvar x = new RealPoint(0.5, 0.5);\nvar y = new RealPoint(2);\ndfieldCorners.apply(x, y);\nprintTformPts(x, y);\n\n// [-100, -100] is transformed to [-99.0,-99.0]\nvar x = new RealPoint(-100, -100);\ndfieldCorners.apply(x, y);\nprintTformPts(x, y);\n\n\n(0.5,0.5) → (3.0,3.0)\n(-100.0,-100.0) → (-99.0,-99.0)\n\n\nBy default, linear interpolation determines the displacement within the array but off of grid values. The nearest value on the border of the array determines the displacement outside the array’s bounds. If instead we want nearest-neighbor interpolation and all out-of-bounds displacements to be zero it can be acheived by:\n\n\nCode\n// interpret our 3d image as a 2d image of vectors\nvar vectorsFrom3D = Views.collapseReal(Views.moveAxis( dfieldData, 0, dfieldData.numDimensions() - 1 ));\n\n// make the displacement field with custom interpolation and boundary extension\nvar dfieldCornersCustom = new DisplacementFieldTransform( \n    Views.interpolate(\n        Views.extendZero(vectorsFrom3D),            // zeros out-of-bounds\n        new NearestNeighborInterpolatorFactory())); // nearest-neighbor interpolation\n\n// [0.4, 0.4] is transformed to [1.4, 1.4]\nvar x = new RealPoint(0.4, 0.4);\nvar y = new RealPoint(2);\ndfieldCornersCustom.apply(x, y);\nprintTformPts(x, y);\n\n// [-100, -100] is transformed to [-100, -100]\nvar x = new RealPoint(-100, -100);\ndfieldCornersCustom.apply(x, y);\nprintTformPts(x, y);\n\n\n(0.4,0.4) → (1.4,1.4)\n(-100.0,-100.0) → (-100.0,-100.0)\n\n\nAnother common requirement is to specify the spacing and offset of the displacement field’s discrete grid. For example, suppose we want the displacements above to be applied to the field of view \\([-10, 10] \\times [-20, 20]\\) rather than the array coordinates \\([0, 1] \\times [0, 1]\\).\n(-10,-20)  ------------------------------------------------  (10,-20)\n           |[1,1]                                    [2,2]|\n           |                                              |                                          \n           |                                              |\n           |                                              |\n           |            (interpolated values)             |\n           |                                              |\n           |                                              |\n           |                                              |\n           |[3,3]                                    [4,4]|\n(-10, 20)  ------------------------------------------------ (10,20)               \nwhere the values outside the box in parenthesis are the coordinates of the corners.\nThis is possible by passing the desired spacing and offset directly to the DisplacementFieldTransform.\n\n\nCode\n/*\n * the spacing and offset below map the array origin [0,0] to [-10,-20]\n * and the element at array index [1,1] to [10,20]\n */\nvar spacing = new double[]{20, 40};\nvar offset = new double[]{-10, -20};\nvar dfieldCornersSpacingOffset = new DisplacementFieldTransform( dfieldData, spacing, offset );\n\n// [-10,-20] is displaced by the vector [1,1], so goes to [-9,-19]\nvar x = new RealPoint(-10, -20);\nvar y = new RealPoint(2);\ndfieldCornersSpacingOffset.apply(x, y);\nprintTformPts(x, y);\n\n// similarly, [10,20] is displaced by the vector [4,4], so goes to [14,24]\nvar x = new RealPoint(10, 20);\ndfieldCornersSpacingOffset.apply(x, y);\nprintTformPts(x, y);\n\n\n(-10.0,-20.0) → (-9.0,-19.0)\n(10.0,20.0) → (14.0,24.0)\n\n\n\n\nTransforming images\nDisplacement fields can also be applied to images. First, let’s open an image:\n\n\nCode\nvar img = ImageJFunctions.wrap(IJ.openImage(\"https://mirror.imagej.net/ij/images/boats.gif\"));\nimg\n\n\n\n\n\n\n\n\n\nNow let’s transform it using our constant valued displacement field. Remember this field has the vector \\([50, -25]\\) everwhere.\nFirst, we’ll define two functions for transforming images:\n\n\nCode\n/*\n * Transform an image of arbitrary size (RandomAccessible) and output an image of size\n * given by resultInterval.\n */ \npublic RandomAccessibleInterval transformImageInterval(RandomAccessible img, RealTransform transform, Interval resultInterval) {    // use n-linear interpolation\n    var interpImg = Views.interpolate(img, new NLinearInterpolatorFactory());\n\n    // transform the image\n    var transformedImg = new RealTransformRandomAccessible(interpImg, transform);\n\n    // rasterize and set bounding box\n    return Views.interval(Views.raster(transformedImg), resultInterval);\n}\n\npublic RandomAccessibleInterval transformImage(RandomAccessibleInterval img, RealTransform transform) {\n    // default out-of-bounds extension and output interval\n    return transformImageInterval(Views.extendZero(img), transform, img);\n}\n\n\n\n\nCode\ntransformImage(img, dfieldConstant);\n\n\n\n\n\n\n\n\n\nNotice that the image is shifted down (+y direction) and to the left (-x direction) : the opposite direction of the displacement vector. This is because the “inverse” transformation (from output coordinates to input coordinates) is needed to transform images. Learn why here.\nNow let’s use what we learned above to make a displacement field whose corners are the corners of the image. We do this by setting the spacing of the displacement field’s coordinate grid as we learned above. This means displacement vector stored at at the array coordinate [1,1] to a new position: [imageWidth, imageHeight].\n\n\nCode\n// some vector field\nvar dfieldData = ArrayImgs.doubles( \n    new double[]{-45, -50, 35, -35, -25, 25, 70, 75},  // the vector data\n    2, 2, 2 ); // the dimensions\n    \n// use the image width and height as the vector fields spacing\nvar dfield = new DisplacementFieldTransform(dfieldData, \n    img.dimension(0), img.dimension(1));\n\n// transform the image\ntransformImage(img, dfield);\n\n\n\n\n\n\n\n\n\nFinally, let’s make a field of random displacements at one-tenth the resolution of the image and apply it.\n\n\nCode\n// create image of random vectors\nvar randDfieldData = ArrayImgs.doubles(2, (img.dimension(0) / 20), (img.dimension(1) / 20));\nrandDfieldData.forEach( x -&gt; { x.set(15 * (Math.random() - 0.5)); });\n    \n// spacing of 20\nvar dfield = new DisplacementFieldTransform(randDfieldData, 20, 20);\n\n// transform the image\ntransformImage(img, dfield);\n\n\n\n\n\n\n\n\n\n\n\nPosition fields\nA position, or coordinate field is similar to a displacement field in that it is also represented by a field of vectors, but those vectors represent positions directly, rather than displacements of the current position.\n\\[\n\\begin{align}\n\\mathbf{x} &: \\text{a position } \\\\\n\\mathbf{v}( \\mathbf{x} ) &: \\text{the vector at position } \\mathbf{x}\\\\\n\\mathbf{v}( \\mathbf{x} ) &: \\text{the output of the transformation}\n\\end{align}\n\\]\nIf we use a constant vector field to make a PositionFieldTransform the output will always be the same:\n\n\nCode\nvar coordinateVector = new double[]{1, 2};\nvar constantVector = new FunctionRealRandomAccessible&lt;&gt;( 2,\n    (x, v) -&gt; { v.setPosition( coordinateVector ); },  // set the vector \n    () -&gt; { return DoubleType.createVector(2); });       // make a 2d vector\n\nvar pfieldConstant = new PositionFieldTransform(constantVector);\n\n// [0, 0] is transformed to [1, 2]\nvar x = new RealPoint(0, 0);\nvar y = new RealPoint(2);\npfieldConstant.apply(x, y);\nprintTformPts(x, y);\n\n// [9999, 9999] is also transformed to [1, 2]\nvar x = new RealPoint(9999, 9999);\nvar y = new RealPoint(2);\npfieldConstant.apply(x, y);\nprintTformPts(x, y);\n\n\n(0.0,0.0) → (1.0,2.0)\n(9999.0,9999.0) → (1.0,2.0)\n\n\nThe Localizables class has some convenience methods for producing images of coordinates. Creating a position field with this image gives the identity. FunctionRandomAccessibles can also be used to generate coordinate images.\n\n\nCode\n// make an image of coordinates\nvar coordinates = Localizables.realRandomAccessible(2);\n\n// extract the x coordinate\nvar xCoordinates = Views.interval(\n    new FunctionRandomAccessible&lt;&gt;( 2,\n        (x, v) -&gt; { v.set( x.getIntPosition(0)); }, \n        UnsignedByteType::new ),\n    new FinalInterval(255, 255));\n\n// extract the y coordinate\nvar yCoordinates = Views.interval(\n    new FunctionRandomAccessible&lt;&gt;( 2,\n        (x, v) -&gt; { v.set( x.getIntPosition( 1 )); }, \n        UnsignedByteType::new ),\n    new FinalInterval(255, 255));\n\ndisplay(\"x coordinates\");\ndisplay(xCoordinates );\ndisplay(\" \");\n\ndisplay(\"y coordinates\");\nyCoordinates\n\n\nx coordinates\n\n\n\n\n\n\n\n\n\n \n\n\ny coordinates\n\n\n\n\n\n\n\n\n\n\n\nCode\n// the identity transformation\nvar identityPfield = new PositionFieldTransform(Localizables.realRandomAccessible(2));\n\n// [0, 0] is transformed to [0, 0]\nvar x = new RealPoint(0, 0);\nvar y = new RealPoint(2);\nidentityPfield.apply(x, y);\nprintTformPts(x, y);\n\n// [9999, 9999] is transformed to [9999, 9999]\nvar x = new RealPoint(9999, 9999);\nidentityPfield.apply(x, y);\nprintTformPts(x, y);\n\n\n(0.0,0.0) → (0.0,0.0)\n(9999.0,9999.0) → (9999.0,9999.0)\n\n\nFor the above examples, notice that the identityPfield does indeed behaves as the identity transformation.\nLet’s make another position field that stretches and compresses the image in a non-linear way.\n\n\nCode\n/*\n * The details of this vector field are not so important,\n * but notice that it is some non-linear function.\n */ \nvar pFieldVectorField = new FunctionRealRandomAccessible&lt;&gt;( 2,\n    (p, v) -&gt; {\n        var cx = img.dimension(0) / 2.0;\n        var cy = img.dimension(1) / 2.0;\n        var ex = Math.exp( -0.020 * (p.getDoublePosition( 0 ) - cx ));\n        var ey = Math.exp( -0.020 * (p.getDoublePosition( 1 ) - cy ));\n        v.setPosition( 10 + 700 / ( 1 + ex ), 0 );\n        v.setPosition( 500 / ( 1 + ey ), 1 );\n    },\n    () -&gt; { return DoubleType.createVector( 2 ); });\n    \n// spacing of 10\nvar spacing = new double[]{1, 1};\nvar offset = new double[]{ img.dimension(0) / 2.0, img.dimension(1) / 2.0 };\nvar pfield = new PositionFieldTransform(pFieldVectorField);\n\n// transform the image\ntransformImage(img, pfield);\n\n\n\n\n\n\n\n\n\nPosition fields can have different input and output dimensions. The length of the vector (first) dimension of the position field indicates its output dimension. The domain of the field indicates the input dimension. So generally, an N+1 dimensional image has N-dimensional inputs since one dimension is the vector dimension. Let’s consider an example.\n\n\nCode\nvar randPfieldData = ArrayImgs.doubles(2, 20, 30, 40, 50); // make a 5d array\n\nvar pfieldRand = new PositionFieldTransform(randPfieldData);\nSystem.out.println(\"input dimensions:  \" + pfieldRand.numSourceDimensions());\nSystem.out.println(\"output dimensions: \" + pfieldRand.numTargetDimensions());\n\n\ninput dimensions:  4\noutput dimensions: 2\n\n\nMake a 1D Function and plot it:\n\n\nCode\n// a 1d signal\nvar sin1d = new FunctionRandomAccessible&lt;&gt;( 1,\n    (p, v) -&gt; {\n        double t = p.getDoublePosition(0);\n        if (t &gt; 250)\n            v.set(64);\n        else \n            v.setReal(150 + ((t/5) * Math.sin(t/10)));\n    },\n    UnsignedByteType::new);\n\n\n\n\nCode\n// plot the 1d function\nvar xpts = new double[256];\nvar ypts = new double[256];\n\nvar access = sin1d.randomAccess();\nIntStream.range(0, 256).forEach( i -&gt; {\n    xpts[i] = i;\n    access.fwd(0);\n    ypts[i] = access.get().getRealDouble();\n});\n\nimport org.knowm.xchart.*;\nimport org.knowm.xchart.style.Styler.LegendPosition;\nimport org.knowm.xchart.style.markers.SeriesMarkers;\n\nvar chart = new XYChartBuilder().width(800).height(600).build();\nchart.getStyler().setChartTitleVisible(false);\nchart.getStyler().setLegendVisible(false);\nchart.getStyler().setChartTitleBoxBackgroundColor(java.awt.Color.white);\nchart.getStyler().setChartBackgroundColor(java.awt.Color.white);\n\nvar series = chart.addSeries(\"function\", xpts, ypts);\nseries.setMarker(SeriesMarkers.NONE);\nBitmapEncoder.getBufferedImage(chart)\n\n\n\n\n\n\n\n\n\n\n\nCode\n/* \n * Create the position field (1D -&gt; 2D)\n *\n * The details of this vector field are not so important,\n * but notice:\n *    1) it is some non-linear function.\n *    2) its input p is a 2D; notice \"p.getDoublePosition(i)\"\n *    3) its output v is 1D (scalar)\n */ \nvar pFieldTransition = new PositionFieldTransform( \n    new FunctionRealRandomAccessible&lt;&gt;( 2, \n        (p, v) -&gt; {\n            double x = p.getDoublePosition( 0 ) - 300;\n            double y = p.getDoublePosition( 1 ) - 300;\n            double r = Math.sqrt( x*x + y*y );\n            double tht = Math.atan2( x, y );\n            v.setPosition(1.2 * r +  32 * tht, 0); \n        }, \n        () -&gt; { return DoubleType.createVector(1); } )\n);\n\n// transform the 1D signal, make a 2D image of size 512 x 512\ntransformImageInterval(sin1d, pFieldTransition, new FinalInterval(512, 512));"
  },
  {
    "objectID": "posts/2022-09-04-how-to-display-imglib2-data.html",
    "href": "posts/2022-09-04-how-to-display-imglib2-data.html",
    "title": "How to display ImgLib2 data in a notebook?",
    "section": "",
    "text": "In this notebook, we will explore how to store, process and visualize data with ImgLib2 in a notebook.\nFirst let’s add the necessary dependencies. We will use ImageJ to load example images and to generate RenderedImage outputs that we can use to render in the notebook. Then, we will import ImgLib2 and the modules to share data between ImgLib2 and ImageJ and the imglib2-realtransform module that includes various transformations.\n\n\nCode\n%mavenRepo scijava.public https://maven.scijava.org/content/groups/public\n\n%maven net.imglib2:imglib2:6.0.0\n%maven jitk:jitk-tps:3.0.3\n%maven net.imagej:ij:1.53t\n%maven net.imglib2:imglib2-ij:2.0.0-beta-46\n%maven net.imglib2:imglib2-realtransform:3.1.2\n\n\nLet’s open one of ImageJ’s example images and show it in the notebook. This uses Spencer Park’s image renderer:\n\n\nCode\nimport ij.*;\n\nvar imp = IJ.openImage(\"https://mirror.imagej.net/ij/images/clown.jpg\");\nimp.getBufferedImage();\n\n\n\n\n\n\n\n\n\nIf we want to work with this image in ImgLib2, we need to provide it as an ImgLib2 interface:\n\n\nCode\nimport net.imglib2.*;\nimport net.imglib2.img.imageplus.*;\n\nvar imp = IJ.openImage(\"https://mirror.imagej.net/ij/images/clown.jpg\");\n// for later use without the compiler losing its mind, we must provide type information\n// for the ImagePlus wrapper, so let's not use var here\nRandomAccessibleInterval&lt;?&gt; rai = ImagePlusImgs.from(imp);\nrai;\n\n\nIntImagePlus [320x200]\n\n\nThere is no default renderer for ImgLib2 interfaces available to the notebook kernel, so we see a default String representation of the result (when rendering this cell the first time). So let’s register some simple renderers that use ImgLib2’s ImageJ bridge and Spencer Park’s image renderer to render ImgLib2 data into the notebook. We add a version that renders the first 2D slice of a RandomAccessibleInterval and a second version that renders a default interval 512x512+0+0 of the 2D slice at position 0 in all other dimensions of an infinite RandomAccessible.\n\n\nCode\nimport io.github.spencerpark.jupyter.kernel.display.common.*;\nimport io.github.spencerpark.jupyter.kernel.display.mime.*;\nimport net.imglib2.img.display.imagej.*;\nimport net.imglib2.view.*;\n\ngetKernelInstance().getRenderer().createRegistration(RandomAccessibleInterval.class)\n        .preferring(MIMEType.IMAGE_PNG)\n        .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n        .register((rai, context) -&gt; Image.renderImage(\n                ImageJFunctions.wrap(rai, rai.toString()).getBufferedImage(),\n                context));\n\ngetKernelInstance().getRenderer().createRegistration(RandomAccessible.class)\n        .preferring(MIMEType.IMAGE_PNG)\n        .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n        .register((ra, context) -&gt; Image.renderImage(\n                ImageJFunctions.wrap(\n                        Views.interval(\n                                ra,\n                                new FinalInterval(\n                                        Arrays.copyOf(\n                                                new long[]{512, 512},\n                                                ra.numDimensions()))),\n                        ra.toString()).getBufferedImage(),\n                context));\n\n\nNow let’s try the same again:\n\n\nCode\nvar imp = IJ.openImage(\"https://mirror.imagej.net/ij/images/clown.jpg\");\n// for later use without the compiler losing its mind, we must provide type information\n// for the ImagePlus wrapper, so let's not use var here\nRandomAccessibleInterval&lt;?&gt; rai = ImagePlusImgs.from(imp);\ndisplay(rai, \"image/gif\");\ndisplay(rai, \"image/jpeg\");\ndisplay(rai, \"image/png\");\n\n\nIntImagePlus [320x200]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11d8908f-67c3-47d4-9615-8e3926265adb\n\n\nOk, great! Let’s try the ‘infinite’ version:\n\n\nCode\nvar ra = Views.extendPeriodic(rai);\nra;\n\n\n\n\n\n\n\n\n\nWonderful! We can of course still render a String representation or alternative encodings with the injected display methods of the kernel:\n\n\nCode\ndisplay(rai, \"text/plain\");\ndisplay(ra, \"text/plain\");\ndisplay(rai, \"image/jpeg\");\ndisplay(ra, \"image/gif\");\n\n\nIntImagePlus [320x200]\n\n\nnet.imglib2.view.ExtendedRandomAccessibleInterval@6d692ecb\n\n\n\n\n\n\n\n\n\nnet.imglib2.view.ExtendedRandomAccessibleInterval@6d692ecb\n\n\n3dac1586-b109-4b27-be06-f7a86a64cd2c\n\n\nYou may have noticed that the output of this cell ends with an obscure identifier. We see this, because we did not catch the output of the display method which provides an identifier for the output object that it generates. This identifier can be used to update the contents of this object. We can use this to render simple animations, e.g. to slice through a 3D volume. Let’s try this with a 3D volume from the ImageJ example images:\n\n\nCode\nvar imp = IJ.openImage(\"https://mirror.imagej.net/ij/images/flybrain.zip\");\nRandomAccessibleInterval&lt;?&gt; rai = ImagePlusImgs.from(imp);\nvar refSlice = display(Views.hyperSlice(rai, 2, rai.dimension(2) / 2), \"image/jpeg\");\nvar refLabel = display(\"slice \" + rai.dimension(2) / 2);\nfor (int z = 0; z &lt; rai.dimension(2); ++z) {\n    var slice = Views.hyperSlice(rai, 2, z);\n    updateDisplay(refSlice, slice, \"image/jpeg\");\n    updateDisplay(refLabel, \"slice \" + z);\n    Thread.sleep(100);\n}\n// for static notebook export\nupdateDisplay(refSlice, Views.hyperSlice(rai, 2, rai.dimension(2) / 2), \"image/jpeg\");\n\n\n\n\n\n\n\n\n\nslice 56\n\n\nOf course, you can only see the animation if you actually run the notebook cell. In a future iteration, we are planning to implement an animated GIF generator for offline animations, but not this time. Let’s see what else we can do with these renderers.\nFirst, let’s apply some transformations to images. Already in the above border extension example as well as in the slicing animation, we have used ImgLib2’s default behavior to apply transformations lazily, i.e. only when a ‘pixel’ is actually queried (e.g. to render it into a RenderedImage raster), the transformations are applied. Transformations can be applied to both coordinates and values. Lets apply some transformations to values:\n\n\nCode\nimport net.imglib2.converter.*;\nimport net.imglib2.type.numeric.*;\n\nvar imp = IJ.openImage(\"https://mirror.imagej.net/ij/images/clown.jpg\");\nRandomAccessibleInterval&lt;ARGBType&gt; rai = ImagePlusImgs.from(imp);\ndisplay(Converters.argbChannel(rai, 1));\ndisplay(\"red\");\ndisplay(Converters.argbChannel(rai, 2));\ndisplay(\"green\");\ndisplay(Converters.argbChannel(rai, 3));\ndisplay(\"blue\");\n\ndisplay(\n        Converters.&lt;ARGBType, ARGBType&gt;convert2(\n                rai,\n                (in, out) -&gt; {\n    \n                    final int argb = in.get();\n                    final double grey = 0.3 * ARGBType.red(argb) + 0.6 * ARGBType.green(argb) + 0.1 * ARGBType.blue(argb);\n                    out.set(ARGBType.rgba(255 - grey, grey, grey, 255));\n                },\n                ARGBType::new));\ndisplay(\"grey to red-cyan ramp\");\n\n\n\n\n\n\n\n\n\nred\n\n\n\n\n\n\n\n\n\ngreen\n\n\n\n\n\n\n\n\n\nblue\n\n\n\n\n\n\n\n\n\ngrey to red-cyan ramp\n\n\n5ea04e32-a511-4b25-8e76-b2aaaf5f3fca\n\n\nAnd now some integer coordinate transformations:\n\n\nCode\ndisplay(Views.invertAxis(rai, 0));\ndisplay(\"flip axis 0\");\n\ndisplay(Views.permute(rai, 0, 1));\ndisplay(\"permute axes\");\n\ndisplay(Views.extendMirrorSingle(rai));\ndisplay(\"mirror extension without repeated border pixels\");\n\ndisplay(Views.subsample(Views.shear(Views.extendPeriodic(rai), 0, 1), 3, 1));\ndisplay(\"extend periodically, shear axis 1 into axis 0, subsample by (3, 1)\");\n\n\n\n\n\n\n\n\n\nflip axis 0\n\n\n\n\n\n\n\n\n\npermute axes\n\n\n\n\n\n\n\n\n\nmirror extension without repeated border pixels\n\n\n\n\n\n\n\n\n\nextend periodically, shear axis 1 into axis 0, subsample by (3, 1)\n\n\naaa10b76-8e83-4b78-9239-fa15d4c143eb\n\n\nWhile most trivial integer transformations such as flipping axes work on intervals, you probably noticed that we had to extend the image to infinity in order to shear it, so ImgLib2 can provide values for coordinates outside of the source interval. For real coordinate transformations we will also need to interpolate values at non-integer coordinates. Finally, in order to render the result, we have to read it from a raster. Let’s do this:\n\n\nCode\nimport net.imglib2.interpolation.randomaccess.*;\nimport net.imglib2.realtransform.*;\n\nvar imp = IJ.openImage(\"https://mirror.imagej.net/ij/images/clown.jpg\");\nRandomAccessibleInterval&lt;ARGBType&gt; rai = ImagePlusImgs.from(imp);\nvar ra = Views.extendValue(rai, new ARGBType(0xff00ff00)); // &lt; green background\nvar interpolated = Views.interpolate(ra, new ClampingNLinearInterpolatorFactory&lt;&gt;()); // n-linear interpolation\n/**\n * This would be\n * var interpolated = Views.interpolate(ra, new NLinearInterpolatorFactory&lt;&gt;());\n * if you have no concern about value overflows\n */\nvar affine = new AffineTransform2D();\nvar transformed = Views.interval(RealViews.affine(interpolated, affine), rai); // shortcut for affines\nvar refImage = display(transformed, \"image/jpeg\");\nvar refLabel = display(\"\", \"text/html\");\n\nfinal int steps = 20;\nfor (int i = 0; i &lt; steps; ++i) {\n    affine.translate(-rai.dimension(0) / 2, -rai.dimension(1) / 2);\n    affine.rotate(Math.PI / 6.0 / steps);\n    affine.scale(1.0 + 0.7 / steps);\n    affine.translate(rai.dimension(0) / 2, rai.dimension(1) / 2);\n    \n    updateDisplay(refImage, Views.interval(transformed, rai), \"image/jpeg\");\n    updateDisplay(\n            refLabel,\n            String.format(\"\"\"\n                            &lt;p&gt;affine transformation matrix:&lt;/p&gt;\n                            &lt;table&gt;\n                            &lt;tr&gt;&lt;td&gt;%.2f&lt;/td&gt;&lt;td&gt;%.2f&lt;/td&gt;&lt;td&gt;%.2f&lt;/td&gt;&lt;/tr&gt;\n                            &lt;tr&gt;&lt;td&gt;%.2f&lt;/td&gt;&lt;td&gt;%.2f&lt;/td&gt;&lt;td&gt;%.2f&lt;/td&gt;&lt;/tr&gt;\n                            &lt;/table&gt;\"\"\",\n                    affine.get(0, 0), affine.get(0, 1), affine.get(0, 2),\n                    affine.get(1, 0), affine.get(1, 1), affine.get(1, 2)), \"text/html\");\n    Thread.sleep(100);\n}\n\n\n\n\n\n\n\n\n\naffine transformation matrix:\n\n\n\n\n1.72\n-0.99\n-16.22\n\n\n0.99\n1.72\n-231.50\n\n\n\n\n\nAffine transformation are probably the most well known and simple real coordinate transformations, but there are many more. Let’s try a ThinplateSplineTransform and format text output with markdown:\n\n\nCode\nvar refImage = display(rai, \"image/jpeg\");\nvar refLabel = display(\"\", \"text/markdown\");\n\nint steps = 20;\ndouble stretch = 40;\nfor (int i = 0; i &lt; steps; ++i) {\n    final double offset = stretch * i / steps;\n    final double[][] p = {\n            {0, rai.dimension(0), 0, rai.dimension(0), rai.dimension(0) * 0.25, rai.dimension(0) * 0.75, rai.dimension(0) * 0.25, rai.dimension(0) * 0.75},\n            {0, 0, rai.dimension(1), rai.dimension(1), rai.dimension(1) * 0.25, rai.dimension(1) * 0.25, rai.dimension(1) * 0.75, rai.dimension(1) * 0.75}\n    };\n    final double[][] q = {\n            {0, rai.dimension(0), 0, rai.dimension(0),\n            rai.dimension(0) * 0.25 + offset , rai.dimension(0) * 0.75 - offset, rai.dimension(0) * 0.25 + offset, rai.dimension(0) * 0.75 - offset},\n            {0, 0, rai.dimension(1), rai.dimension(1),\n            rai.dimension(1) * 0.25 + offset, rai.dimension(1) * 0.25 + offset, rai.dimension(1) * 0.75 - offset, rai.dimension(1) * 0.75 - offset}\n    };\n    final var transform = new ThinplateSplineTransform(p, q);\n    final var warped = new RealTransformRandomAccessible&lt;&gt;(interpolated, transform);\n    String text = \"\"\"\nthinplate spline transformation controls points:\n            \n| | p&lt;sub&gt;x&lt;/sub&gt; | p&lt;sub&gt;y&lt;/sub&gt; | q&lt;sub&gt;x&lt;/sub&gt; | q&lt;sub&gt;y&lt;/sub&gt; |\n| --- | ---: | ---: | ---: | ---: |\n\"\"\";\n    for (int j = 0; j &lt; p[0].length; ++j)\n        text += String.format(\"\"\"\n| %d | %.2f | %.2f | %.2f | %.2f |\n\"\"\",\n                j, p[0][j], p[1][j], q[0][j], q[1][j]);                \n\n    updateDisplay(refImage, Views.interval(warped, rai), \"image/jpeg\");\n    updateDisplay(refLabel, text, \"text/markdown\");\n\n    Thread.sleep(100);\n}\n\n\n\n\n\n\n\n\n\nthinplate spline transformation controls points:\n\n\n\n\npx\npy\nqx\nqy\n\n\n\n\n0\n0.00\n0.00\n0.00\n0.00\n\n\n1\n320.00\n0.00\n320.00\n0.00\n\n\n2\n0.00\n200.00\n0.00\n200.00\n\n\n3\n320.00\n200.00\n320.00\n200.00\n\n\n4\n80.00\n50.00\n118.00\n88.00\n\n\n5\n240.00\n50.00\n202.00\n88.00\n\n\n6\n80.00\n150.00\n118.00\n112.00\n\n\n7\n240.00\n150.00\n202.00\n112.00"
  },
  {
    "objectID": "posts/2022-10-30-streams/2022-10-30-streams.html",
    "href": "posts/2022-10-30-streams/2022-10-30-streams.html",
    "title": "Adding Stream support to ImgLib2",
    "section": "",
    "text": "(first posted at image.sc)"
  },
  {
    "objectID": "posts/2022-10-30-streams/2022-10-30-streams.html#access-img-pixels-as-a-stream",
    "href": "posts/2022-10-30-streams/2022-10-30-streams.html#access-img-pixels-as-a-stream",
    "title": "Adding Stream support to ImgLib2",
    "section": "Access Img pixels as a Stream",
    "text": "Access Img pixels as a Stream\nThe first addition is that every IterableRealInterval&lt;T&gt; (and sub-classes like IterableInterval, Img, …) can now provide (sequential or parallel) streams over its elements.\npublic interface IterableRealInterval&lt;T&gt; extends RealInterval, Iterable&lt;T&gt; {\n    ...\n    Stream&lt;T&gt; stream();\n    Stream&lt;T&gt; parallelStream();\n}\nThis is entirely equivalent to java.util.Collection\npublic interface Collection&lt;T&gt; extends Iterable&lt;T&gt; {\n    ...\n    Stream&lt;T&gt; stream();\n    Stream&lt;T&gt; parallelStream();\n}\nand allows to operate on pixel values.\nEncounter order of the streams is always compatible with cursor(). That is, Views.flatIterable(img).stream() yields elements in flat iteration order.\nStreams can be used, for example, to set all pixels of an Img to some value:\nstatic &lt;T extends Type&lt;T&gt;&gt; void fill(Img&lt;T&gt; img, T value) {\n    \n    img.stream().forEach(t-&gt;t.set(value));\n}\nto compute the sum of all values in an Img:\nstatic double sum(Img&lt;DoubleType&gt; img) {\n\n    return img.stream()\n            .mapToDouble(DoubleType::get)\n            .sum();\n}\nor to find the maximum value in an Img:\nstatic double max(Img&lt;DoubleType&gt; img) {\n\n    return img.stream()\n            .mapToDouble(DoubleType::get)\n            .max().getAsDouble();\n}\nIn particular the latter two examples, where the terminal operation is some form of reduction, allow for more convenient parallelization than the alternatives. Computing the maximum value in parallel is as simple as\nstatic double max(Img&lt;DoubleType&gt; img) {\n\n    return img.parallelStream()\n            .mapToDouble(DoubleType::get)\n            .max().getAsDouble();\n}\nDoing the same with LoopBuilder currently requires to parallelize over chunks, collect partial results into mutable holder objects, and implement the reduction of partial results into the final result."
  },
  {
    "objectID": "posts/2022-10-30-streams/2022-10-30-streams.html#access-img-values-and-positions-as-a-stream",
    "href": "posts/2022-10-30-streams/2022-10-30-streams.html#access-img-values-and-positions-as-a-stream",
    "title": "Adding Stream support to ImgLib2",
    "section": "Access Img values and positions as a Stream",
    "text": "Access Img values and positions as a Stream\nA stream of only pixel values, without access to their positions is rather limiting. For example, we would often be interested in the location of the image maximum, not only the value. To achieve this, there is a new utility class net.imglib2.stream.Streams, with methods\npublic static &lt;T&gt; Stream&lt;RealLocalizableSampler&lt;T&gt;&gt; localizable(IterableRealInterval&lt;T&gt; interval)\npublic static &lt;T&gt; Stream&lt;RealLocalizableSampler&lt;T&gt;&gt; localizing(IterableRealInterval&lt;T&gt; interval)\npublic static &lt;T&gt; Stream&lt;LocalizableSampler&lt;T&gt;&gt; localizable(IterableInterval&lt;T&gt; interval)\npublic static &lt;T&gt; Stream&lt;LocalizableSampler&lt;T&gt;&gt; localizing(IterableInterval&lt;T&gt; interval)\nthat allow to create Streams of LocalizableSampler&lt;T&gt; of the pixels of an IterableInterval (and analogous for IterableRealInterval). You can think of LocalizableSampler&lt;T&gt; as a Cursor&lt;T&gt; which cannot be moved, which is more or less what the default implementation does under the hood.\nThe localizable and localizing variants are analogous to cursor() and localizingCursor() The Stream returned by localizable computes element locations only when asked to (with potentially higher per-element cost). The Stream returned by localizing tracks element locations always (in general faster, but potentially unnecessary).\nFor example, to fill image pixels with position-dependent values, we would use localizing, because we require the position of each element.\nstatic void fractal() {\n    \n    Img&lt;UnsignedByteType&gt; img = ArrayImgs.unsignedBytes(1000, 1000);\n    Streams.localizing(img)\n            .parallel()\n            .forEach(s -&gt; s.get().set(\n                    mandelbrot(\n                            (s.getDoublePosition(0) - 800) / 500,\n                            (s.getDoublePosition(1) - 500) / 500)\n            ));\n    BdvFunctions.show(img, \"mandelbrot\", Bdv.options().is2D());\n}\n\n\n\nimage|616x500\n\n\nConversely, to compute the maximum value and its location in an image, we would use localizable, because we only ask for the position of one element (the maximum).\nstatic void printMax(Img&lt;IntType&gt; img) {\n\n    Optional&lt;LocalizableSampler&lt;IntType&gt;&gt; optionalMax =\n            Streams.localizable(img)\n                    .parallel()\n                    .map(LocalizableSampler::copy)\n                    .max(Comparator.comparingInt(c -&gt; c.get().get()));\n    LocalizableSampler&lt;IntType&gt; max = optionalMax.get();\n    System.out.println(\"max position = \" + Util.printCoordinates(max));\n    System.out.println(\"max value = \" + max.get().getInteger());\n}\n(In both cases, it is fine to chose the respectively other variant with no change in behaviour, and only limited performance impact.)"
  },
  {
    "objectID": "posts/2022-10-30-streams/2022-10-30-streams.html#pitfalls",
    "href": "posts/2022-10-30-streams/2022-10-30-streams.html#pitfalls",
    "title": "Adding Stream support to ImgLib2",
    "section": "Pitfalls",
    "text": "Pitfalls\nThe T elements of the stream are proxies that are re-used, as usual in ImgLib2. Explicit copying operations must be added if stream elements are supposed to be retained (by stateful intermediate or terminal operations).\nFor example, to collect all DoubleType values between 0 and 1 into a list:\nList&lt; DoubleType &gt; values = img.stream()\n    .filter( t -&gt; t.get() &gt;= 0.0 && t.get() &lt;= 1.0 )\n    .map( DoubleType::copy ) // &lt;-- this is important!\n    .collect( Collectors.toList() );\nThe .map(DoubleType::copy) operation is necessary, otherwise the values list will contain many duplicates of the same (re-used proxy) DoubleType instance. The copy could also be done before the .filter(...) operation, but it’s better to do it as late as possible to avoid unnecessary creation of objects.\nLikewise, the .map(LocalizableSampler::copy) in the printMax() example above is required. There is ongoing work to reduce the necessity of explicit copy operations. For example, in the printMax() example, the .max() operation of the stream could be overridden to only copy when a new maximum candidate is encountered.\nNote, that already the current implementation takes care not to re-use proxies across parallel execution, so threads of a parallelStream() will not interfere."
  },
  {
    "objectID": "posts/2022-10-30-streams/2022-10-30-streams.html#implementation-details",
    "href": "posts/2022-10-30-streams/2022-10-30-streams.html#implementation-details",
    "title": "Adding Stream support to ImgLib2",
    "section": "Implementation details",
    "text": "Implementation details\n\nBoth, pure-value streams and value-and-position streams make use of LocalizableSpliterator&lt;T&gt;. LocalizableSpliterator&lt;T&gt; extends Spliterator and Localizable, similiar to Cursor extending Iterator and Localizable.\nThere are default LocalizableSpliterator&lt;T&gt; (and RealLocalizableSpliterator&lt;T&gt;) implementations based on Cursor&lt;T&gt; (and RealCursor&lt;T&gt;). Therefore, the new streams API works for every IterableRealInterval, without the need to touch existing implementations.\nAdditionally, the standard Img classes have custom LocalizableSpliterator&lt;T&gt;, that leverage knowledge of underlying storage for improved performance."
  },
  {
    "objectID": "posts/2022-10-30-streams/2022-10-30-streams.html#performance",
    "href": "posts/2022-10-30-streams/2022-10-30-streams.html#performance",
    "title": "Adding Stream support to ImgLib2",
    "section": "Performance",
    "text": "Performance\nIt’s complicated…\nOne the one hand, there comes considerable performance overhead in replacing simple loops with stream operations. This has nothing to do with ImgLib2, it is just a “feature” of the underlying machinery. This can be observed for example by benchmarking looping over an int[] array:\nint[] values = new int[4_000_000];\n\n@Benchmark\npublic long benchmarkForLoopArray() {\n    long count = 0;\n    for (int value : values) {\n        if (value &gt; 127)\n            ++count;\n    }\n    return count;\n}\n\n@Benchmark\npublic long benchmarkStreamArray() {\n    return IntStream.of(values).filter(value -&gt; value &gt; 127).count();\n}\nThe result is\nBenchmark                                          Mode  Cnt   Score   Error  Units\nArrayStreamBenchmark.benchmarkForLoopArray         avgt   15   2,563 ± 0,026  ms/op\nArrayStreamBenchmark.benchmarkStreamArray          avgt   15  11,052 ± 0,022  ms/op\nThat is, the Stream version is &gt; 4 times slower. Equivalent performance overhead often can be observed in ImgLib2, when replacing Cursor based loops with Stream operations.\nOn the other hand, custom Spliterator implementations sometimes benefit more than cursors from tuning to the underlying storage. (Because iteration is “internal” with the spliterator, while the cursor must return control to the caller after every visited element.) For example, consider the following benchmark method (equivalent code for other variations omitted, see github for full details):\n@Benchmark\npublic long benchmarkStream() {\n    long sum = Streams.localizable(img)\n            .mapToLong(s -&gt; s.get().get()\n                    + s.getIntPosition(0)\n                    + s.getIntPosition(1)\n                    + s.getIntPosition(2)\n            ).sum();\n    return sum;\n}\nThe result looks like\nBenchmark                                                            (imgType)  Mode  Cnt   Score   Error  Units\nLocalizableSamplerStreamBenchmark.benchmarkCursor                     ArrayImg  avgt   15  10,097 ± 0,046  ms/op\nLocalizableSamplerStreamBenchmark.benchmarkLocalizingCursor           ArrayImg  avgt   15   3,846 ± 0,020  ms/op\nLocalizableSamplerStreamBenchmark.benchmarkLocalizingStream           ArrayImg  avgt   15   3,337 ± 0,027  ms/op\nLocalizableSamplerStreamBenchmark.benchmarkLocalizingParallelStream   ArrayImg  avgt   15   0,962 ± 0,583  ms/op\nThat is, the performance difference between localizing and non-localizing Cursors is much more pronounced than the difference between Cursor loop and Stream. In fact, the Stream version is even faster than the localizingCursor version. On top of that, it is trivial to parallelize.\nFinally, we did not investigate polymorphism effects so far. It is very much possible that this affects performance and we may have to investigate employing LoopBuilders class-copying mechanism to counter these effects.\nIn summary, I think one should not hesitate to use Streams where it makes sense from a readability and ease-of-use perspective. If performance is a critical concern, it is best to benchmark various approaches, because the behaviour is not easy to predict."
  },
  {
    "objectID": "posts/2022-09-27-n5-imglib2.html",
    "href": "posts/2022-09-27-n5-imglib2.html",
    "title": "How to work with the N5 API and ImgLib2?",
    "section": "",
    "text": "In this notebook, we will learn how to work with the N5 API and ImgLib2.\nThe N5 API unifies block-wise access to potentially very large n-dimensional data over a variety of storage backends. Those backends currently are the simple N5 format on the local filesystem, Google Cloud and AWS-S3, the HDF5 file format and Zarr. The ImgLib2 bindings use this API to make this data available as memory cached lazy cell images through ImgLib2.\nThis notebook uses code and data examples from the ImgLib2 large data tutorial I2K2020 workshop (GitHub repository).\nFirst let’s add the necessary dependencies. We will load the n5-ij module which will transitively load ImgLib2 and all the N5 API modules that we will be using in this notebook. It will also load ImageJ which we will use to display data.\n\n\nCode\n%%loadFromPOM\n&lt;repository&gt;\n    &lt;id&gt;scijava.public&lt;/id&gt;\n    &lt;url&gt;https://maven.scijava.org/content/groups/public&lt;/url&gt;\n&lt;/repository&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.janelia.saalfeldlab&lt;/groupId&gt;\n    &lt;artifactId&gt;n5&lt;/artifactId&gt;\n    &lt;version&gt;2.5.1&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.janelia.saalfeldlab&lt;/groupId&gt;\n    &lt;artifactId&gt;n5-ij&lt;/artifactId&gt;\n    &lt;version&gt;3.2.2&lt;/version&gt;\n&lt;/dependency&gt;\n\n\nNow, we register a simple renderer that uses ImgLib2’s ImageJ bridge and Spencer Park’s image renderer to render the first 2D slice of a RandomAccessibleInterval into the notebook. We also add a renderer for arrays and maps, because we want to list directories and attributes maps later.\n\n\nCode\nimport com.google.gson.*;\nimport io.github.spencerpark.jupyter.kernel.display.common.*;\nimport io.github.spencerpark.jupyter.kernel.display.mime.*;\nimport net.imglib2.img.display.imagej.*;\nimport net.imglib2.view.*;\nimport net.imglib2.*;\n\ngetKernelInstance().getRenderer().createRegistration(RandomAccessibleInterval.class)\n        .preferring(MIMEType.IMAGE_PNG)\n        .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n        .register((rai, context) -&gt; Image.renderImage(\n                ImageJFunctions.wrap(rai, rai.toString()).getBufferedImage(),\n                context));\n\ngetKernelInstance().getRenderer().createRegistration(String[].class)\n        .preferring(MIMEType.TEXT_PLAIN)\n        .supporting(MIMEType.TEXT_HTML, MIMEType.TEXT_MARKDOWN)\n        .register((array, context) -&gt; Text.renderCharSequence(Arrays.toString(array), context));\n\ngetKernelInstance().getRenderer().createRegistration(long[].class)\n        .preferring(MIMEType.TEXT_PLAIN)\n        .supporting(MIMEType.TEXT_HTML, MIMEType.TEXT_MARKDOWN)\n        .register((array, context) -&gt; Text.renderCharSequence(Arrays.toString(array), context));\n\ngetKernelInstance().getRenderer().createRegistration(Map.class)\n        .preferring(MIMEType.TEXT_PLAIN)\n        .supporting(MIMEType.TEXT_HTML, MIMEType.TEXT_MARKDOWN)\n        .register((map, context) -&gt; Text.renderCharSequence(map.toString(), context));\n\n\nWe will now open N5 datasets from some sources as lazy-loading ImgLib2 cell images. For opening the N5 readers, we will use the helper class N5Factory which parses the URL and/ or some magic byte in file headers to pick the right reader or writer for the various possible N5 backends. If you know which backend you are using, you should probably use the appropriate implementation directly, it’s not difficult.\n\n\nCode\nimport ij.*;\nimport net.imglib2.converter.*;\nimport net.imglib2.type.numeric.integer.*;\nimport org.janelia.saalfeldlab.n5.*;\nimport org.janelia.saalfeldlab.n5.ij.*;\nimport org.janelia.saalfeldlab.n5.imglib2.*;\n\n/* make an N5 reader, we start with a public container on AWS S3 */\nfinal var n5Url = \"https://janelia-cosem.s3.amazonaws.com/jrc_hela-2/jrc_hela-2.n5\";\nfinal var n5Group = \"/em/fibsem-uint16\";\nfinal var n5Dataset = n5Group + \"/s4\";\nfinal var n5 = new N5Factory().openReader(n5Url);\n\n/* open a dataset as a lazy loading ImgLib2 cell image */\nfinal RandomAccessibleInterval&lt;UnsignedShortType&gt; rai = N5Utils.open(n5, n5Dataset);\n\n/* This is a 3D volume, so let's show the center slice */\nViews.hyperSlice(rai, 2, rai.dimension(2) / 2);\n\n\nlog4j:WARN No appenders could be found for logger (com.amazonaws.auth.AWSCredentialsProviderChain).\nlog4j:WARN Please initialize the log4j system properly.\nlog4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n\n\nCould not load AWS credentials, falling back to anonymous.\n\n\n\n\n\n\n\n\n\nThat’s a bit low on contrast, let’s make it look like TEM, and let’s show a few of those hyperslices through the 3D volume:\n\n\nCode\nvar raiContrast = Converters.convert(\n        rai,\n        (a, b) -&gt; b.setReal(Math.max(0, Math.min(255, 255 - 255 * (a.getRealDouble() - 26000) / 6000))),\n        new UnsignedByteType());\ndisplay(Views.hyperSlice(raiContrast, 2, rai.dimension(2) / 10 * 4), \"image/jpeg\");\ndisplay(Views.hyperSlice(raiContrast, 2, rai.dimension(2) / 2), \"image/jpeg\");\ndisplay(Views.hyperSlice(raiContrast, 2, rai.dimension(2) / 10 * 6), \"image/jpeg\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6e32749d-48d5-4c52-be9b-41c43bae02f4\n\n\nWe can list the attributes and their types of every group or dataset, and read any of them into matching types:\n\n\nCode\nvar groupAttributes = n5.listAttributes(n5Group);\nvar datasetAttributes = n5.listAttributes(n5Dataset);\n\ndisplay(\n    \"**\" + n5Group + \"** attributes are ```\" +\n        groupAttributes.toString().replace(\", \", \",\\n\").replace(\"{\", \"{\\n\") + \"```\",\n    \"text/markdown\");\ndisplay(\n    \"**\" + n5Dataset + \"** attributes are ```\" +\n        datasetAttributes.toString().replace(\", \", \",\\n\").replace(\"{\", \"{\\n\") + \"```\",\n    \"text/markdown\");\n\nvar n5Version = n5.getAttribute(\"/\", \"n5\", String.class);\nvar dimensions = n5.getAttribute(n5Dataset, \"dimensions\", long[].class);\nvar compression = n5.getAttribute(n5Dataset, \"compression\", Compression.class);\nvar dataType = n5.getAttribute(n5Dataset, \"dataType\", DataType.class);\n\ndisplay(n5Version);\ndisplay(dimensions);\ndisplay(compression);\ndisplay(dataType);\n\n\n/em/fibsem-uint16 attributes are { pixelResolution=class java.lang.Object, multiscales=class [Ljava.lang.Object;, n5=class java.lang.String, scales=class [Ljava.lang.Object;, axes=class [Ljava.lang.String;, name=class java.lang.String, units=class [Ljava.lang.String;}\n\n\n/em/fibsem-uint16/s4 attributes are { transform=class java.lang.Object, pixelResolution=class java.lang.Object, dataType=class java.lang.String, name=class java.lang.String, compression=class java.lang.Object, blockSize=class [J, dimensions=class [J}\n\n\n2.0.0\n\n\n[750, 100, 398]\n\n\norg.janelia.saalfeldlab.n5.GzipCompression@673562cc\n\n\nuint16\n\n\n6c5c9bc2-ea28-4685-9658-a8fbf3c65df4\n\n\nLet’s save the contrast adjusted uin8 version of the volume into three N5 supported containers (N5, Zarr, and HDF5), parallelize writing for N5 and Zarr:\n\n\nCode\nimport java.nio.file.*;\n\n/* create a temporary directory */\nPath tmpDir = Files.createTempFile(\"\", \"\");\nFiles.delete(tmpDir);\nFiles.createDirectories(tmpDir);\nvar tmpDirStr = tmpDir.toString();\n\ndisplay(tmpDirStr);\n\n/* get the dataset attributes (dataType, compression, blockSize, dimensions) */\nfinal var attributes = n5.getDatasetAttributes(n5Dataset);\n\n/* use 10 threads to parallelize copy */\nfinal var exec = Executors.newFixedThreadPool(10);\n\n/* save this dataset into a filsystem N5 container */\ntry (final var n5Out = new N5Factory().openFSWriter(tmpDirStr + \"/test.n5\")) {\n    N5Utils.save(raiContrast, n5Out, n5Dataset, attributes.getBlockSize(), attributes.getCompression(), exec);\n}\n\n/* save this dataset into a filesystem Zarr container */\ntry (final var zarrOut = new N5Factory().openZarrWriter(tmpDirStr + \"/test.zarr\")) {\n    N5Utils.save(raiContrast, zarrOut, n5Dataset, attributes.getBlockSize(), attributes.getCompression(), exec);\n}\n\n/* save this dataset into an HDF5 file, parallelization does not help here */\ntry (final var hdf5Out = new N5Factory().openHDF5Writer(tmpDirStr + \"/test.hdf5\")) {\n    N5Utils.save(raiContrast, hdf5Out, n5Dataset, attributes.getBlockSize(), attributes.getCompression());\n}\n\n/* shot down the executor service */\nexec.shutdown();\n\ndisplay(Files.list(tmpDir).map(a -&gt; a.toString()).toArray(String[]::new));\n\n\n/tmp/303790804299695858\n\n\n[/tmp/303790804299695858/test.hdf5, /tmp/303790804299695858/test.n5, /tmp/303790804299695858/test.zarr]\n\n\nd55081b3-d9fd-4208-9bae-181c9253712a\n\n\nNow let us look at them and see if they all contain the same data:\n\n\nCode\ntry (final var n5 = new N5Factory().openReader(tmpDirStr + \"/test.n5\")) {\n    final RandomAccessibleInterval&lt;UnsignedByteType&gt; rai = N5Utils.open(n5, n5Dataset);\n    display(Views.hyperSlice(rai, 2, rai.dimension(2) / 2), \"image/jpeg\");\n}\n\ntry (final var n5 = new N5Factory().openReader(tmpDirStr + \"/test.zarr\")) {\n    final RandomAccessibleInterval&lt;UnsignedByteType&gt; rai = N5Utils.open(n5, n5Dataset);\n    display(Views.hyperSlice(rai, 2, rai.dimension(2) / 2), \"image/jpeg\");    \n}\n\ntry (final var n5 = new N5Factory().openReader(tmpDirStr + \"/test.hdf5\")) {\n    final RandomAccessibleInterval&lt;UnsignedByteType&gt; rai = N5Utils.open(n5, n5Dataset);\n    display(Views.hyperSlice(rai, 2, rai.dimension(2) / 2), \"image/jpeg\");        \n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s clean up temporary storage before we end this tutorial.\n\n\nCode\ntry (var n5 = new N5Factory().openWriter(tmpDirStr + \"/test.n5\")) {\n    n5.remove();\n}\ntry (var n5 = new N5Factory().openWriter(tmpDirStr + \"/test.zarr\")) {\n    n5.remove();\n}\ntry (var n5 = new N5Factory().openWriter(tmpDirStr + \"/test.hdf5\")) {\n    n5.remove();\n}\nFiles.delete(tmpDir);"
  },
  {
    "objectID": "posts/2022-05-02-juliaset-lambda.html",
    "href": "posts/2022-05-02-juliaset-lambda.html",
    "title": "Juliaset Lambda",
    "section": "",
    "text": "Import dependencies. BigDataViewer Vistools is the convenience API that we use to display the results of our experiments and it includes all ImgLib2 related dependencies that we need.\n\n\nCode\n%mavenRepo scijava.public https://maven.scijava.org/content/groups/public\n%maven sc.fiji:bigdataviewer-vistools:1.0.0-beta-29\n%maven net.imagej:ij:1.53t\n%maven net.imglib2:imglib2-ij:2.0.0-beta-46\n\n\nWe define the Juliaset as a function in 2D real space using a BiConsumer lambda. The BiConsumer receives two parameters, the first one (x) is the 2D coordinate, the second one (y) is the target of the function whose value will be set in place, here we use an IntType. We also have to provide a Supplier for instances of the target such that multiple threads can each create their own.\n\n\nCode\nimport io.github.spencerpark.jupyter.kernel.display.common.*;\nimport io.github.spencerpark.jupyter.kernel.display.mime.*;\nimport net.imglib2.img.display.imagej.*;\nimport net.imglib2.view.*;\nimport net.imglib2.*;\n\ngetKernelInstance().getRenderer().createRegistration(RandomAccessibleInterval.class)\n        .preferring(MIMEType.IMAGE_PNG)\n        .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n        .register((rai, context) -&gt; Image.renderImage(\n                ImageJFunctions.wrap(rai, rai.toString()).getBufferedImage(),\n                context));\n\ngetKernelInstance().getRenderer().createRegistration(RandomAccessible.class)\n        .preferring(MIMEType.IMAGE_PNG)\n        .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n        .register((ra, context) -&gt; Image.renderImage(\n                ImageJFunctions.wrap(\n                        Views.interval(\n                                ra,\n                                new FinalInterval(\n                                        Arrays.copyOf(\n                                                new long[]{512, 512},\n                                                ra.numDimensions()))),\n                        ra.toString()).getBufferedImage(),\n                context));\n\ngetKernelInstance().getRenderer().createRegistration(RealRandomAccessible.class)\n        .preferring(MIMEType.IMAGE_PNG)\n        .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n        .register((rra, context) -&gt; Image.renderImage(\n                ImageJFunctions.wrap(\n                        Views.interval(\n                                Views.raster(rra),\n                                new FinalInterval(\n                                        Arrays.copyOf(\n                                                new long[]{512, 512},\n                                                rra.numDimensions()))),\n                        rra.toString()).getBufferedImage(),\n                context));\n\n\n\n\nCode\nimport bdv.util.*;\nimport net.imglib2.position.FunctionRealRandomAccessible;\nimport net.imglib2.type.numeric.integer.*;\nimport net.imglib2.util.Intervals;\nimport net.imglib2.realtransform.*;\n\nvar juliaset = new FunctionRealRandomAccessible&lt;&gt;(\n    2,\n    (x, fx) -&gt; {\n        int i = 0;\n        double v = 0, c = x.getDoublePosition(0), d = x.getDoublePosition(1);\n        for (; i &lt; 255 && v &lt; 4096; ++i) {\n            final double e = c * c - d * d;\n            d = 2 * c * d;\n            c = e + 0.3;\n            d += 0.6;\n            v = Math.sqrt(c * c + d * d);\n            ++i;\n        }\n        fx.set(i);\n    },\n    UnsignedByteType::new);\n\n\nNow we show this function with BigDataViewer. Use your mouse and keyboard to zoom in until you reach the precision limit of double.\n\n\nCode\nBdvFunctions.show(\n    juliaset,\n    Intervals.createMinMax(-1, -1, 1, 1),\n    \"bla\",\n    BdvOptions.options().is2D()).setDisplayRange(0, 127);\n\n\n\n\nCode\nvar transform = new ScaleAndTranslation(new double[]{255, 255}, new double[]{255, 255});\nvar transformed = RealViews.affineReal(juliaset, transform);\ntransformed;\n\n\n\n\n\n\n\n\n\nCool? I think so! Now let’s embed one of the two parameters of the Juliaset as a third dimension. The code is almost the same except that we introduce a a variable a.\n\n\nCode\nvar juliaset3 = new FunctionRealRandomAccessible&lt;&gt;(\n    3,\n    (x, fx) -&gt; {\n        int i = 0;\n        double v = 0, c = x.getDoublePosition(0), d = x.getDoublePosition(1), a = x.getDoublePosition(2);\n        for (; i &lt; 255 && v &lt; 4096; ++i) {\n            final double e = c * c - d * d;\n            d = 2 * c * d;\n            c = e + a;\n            d += 0.6;\n            v = Math.sqrt(c * c + d * d);\n            ++i;\n        }\n        fx.set(i);\n    },\n    IntType::new);\n\n\nAnd now we show this as a 3D volume in BigDataViewer. You can scroll through the ‘z’-dimension or arbitrarily slice through the 3D volume.\n\n\nCode\nBdvFunctions.show(\n    juliaset3,\n    Intervals.createMinMax(-1, -1, -1, 1, 1, 1),\n    \"Juliaset3\",\n    BdvOptions.options()).setDisplayRange(0, 127);\n\n\nThis was using a stateless function, i.e. each RealRandomAccess uses the same instance. If you have stateful functions, you want to use a function provider. Spot the difference:\n\n\nCode\nfinal var rnd = new Random();\nvar juliaset3Stripes = new FunctionRealRandomAccessible&lt;&gt;(\n    3,\n    () -&gt;\n    { \n        final int offset = rnd.nextInt(100);\n        return (x, fx) -&gt; {\n            int i = 0;\n            double v = 0, c = x.getDoublePosition(0), d = x.getDoublePosition(1), a = x.getDoublePosition(2);\n            for (; i &lt; 255 && v &lt; 4096; ++i) {\n                final double e = c * c - d * d;\n                d = 2 * c * d;\n                c = e + a;\n                d += 0.6;\n                v = Math.sqrt(c * c + d * d);\n                ++i;\n            }\n            fx.set(i + offset);\n        };\n    },\n    IntType::new);\n\n\n\n\nCode\nBdvFunctions.show(\n    juliaset3Stripes,\n    Intervals.createMinMax(-1, -1, -1, 1, 1, 1),\n    \"Juliaset3\",\n    BdvOptions.options()).setDisplayRange(0, 127);"
  },
  {
    "objectID": "posts/2022-08-08-keymaps/2022-08-08-keymaps.html",
    "href": "posts/2022-08-08-keymaps/2022-08-08-keymaps.html",
    "title": "User-configurable Keymaps",
    "section": "",
    "text": "While developing the BDV Preferences dialog, a “pattern” has emerged of how we wire up the shortcut and action definitions. This tutorial explains the current recommended way of doing that. We give some background about using ui-behaviour etc. Feel free to just skip to the end for the recommended pattern."
  },
  {
    "objectID": "posts/2022-08-08-keymaps/2022-08-08-keymaps.html#introduction",
    "href": "posts/2022-08-08-keymaps/2022-08-08-keymaps.html#introduction",
    "title": "User-configurable Keymaps",
    "section": "Introduction",
    "text": "Introduction\nIn BigDataViewer 10.4 we added a Preferences dialog. This makes settings more user accessible, that previously could only be made through editing config files. In particular, users can now easily override BigDataViewer keybindings to their liking.\nIt is also possible to define and switch between multiple sets of keybindings. For example, in Mastodon, we have predefined keymaps that have * basic BDV key bindings, but many shortcuts remapped to navigate along a cell lineage, or * full BDV key bindings, at the expense of more complicated shortcuts for cell lineage navigation.\nOn top of these users can define their own completely customised keymaps.\nThis is all based on ui-bahaviour, which several tools (BDV-based and otherwise) already use for managing shortcuts. While developing the Mastodon Preferences dialog, and now carrying over to BigDataViewer, a pattern has emerged of how we wire up the shortcut and action definitions. It would be great if this would become a blueprint for actions in other tools, because a) that will make the code easier to understand and b) facilitate reuse of action definitions across projects.\nWe work towards the recommended pattern, from scratch, in a series of examples that you can also find on github.\n\n\nCode\n%%loadFromPOM\n&lt;repository&gt;\n    &lt;id&gt;scijava.public&lt;/id&gt;\n    &lt;url&gt;https://maven.scijava.org/content/groups/public&lt;/url&gt;\n&lt;/repository&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;sc.fiji&lt;/groupId&gt;\n    &lt;artifactId&gt;bigdataviewer-core&lt;/artifactId&gt;\n    &lt;version&gt;10.4.3&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.scijava&lt;/groupId&gt;\n    &lt;artifactId&gt;ui-behaviour&lt;/artifactId&gt;\n    &lt;version&gt;2.0.7&lt;/version&gt;\n&lt;/dependency&gt;"
  },
  {
    "objectID": "posts/2022-08-08-keymaps/2022-08-08-keymaps.html#setting-up-shortcuts-through-ui-behaviour",
    "href": "posts/2022-08-08-keymaps/2022-08-08-keymaps.html#setting-up-shortcuts-through-ui-behaviour",
    "title": "User-configurable Keymaps",
    "section": "Setting up shortcuts through ui-behaviour",
    "text": "Setting up shortcuts through ui-behaviour\nLets look at a basic example of integrating ui-beahviour in a AWT/Swing application.\nWe need a minimal application to play with: MainPanel is a JPanel containing (only) a single JLabel displaying the text \"hello\". The displayed text can be changed by the setText(String) method. We will use this to define different mock “actions”.\n\n\nCode\n/*\n#| include: false\n*/\nimport java.awt.BorderLayout;\nimport java.awt.Dimension;\nimport javax.swing.JFrame;\nimport javax.swing.JLabel;\nimport javax.swing.JPanel;\nimport javax.swing.border.EmptyBorder;\n\n\n\n\nCode\npublic class MainPanel extends JPanel\n{\n    private final JLabel label;\n\n    public MainPanel()\n    {\n        setLayout( new BorderLayout() );\n        setBorder( new EmptyBorder( 0, 20, 0, 0 ) );\n        setFocusable( true );\n\n        label = new JLabel( \"hello\" );\n        add( label, BorderLayout.CENTER );\n    }\n\n    public void setText( final String text )\n    {\n        label.setText( text );\n    }\n}\n\n\nLet’s instantiate a MainPanel and show it in a JFrame.\n\n\nCode\nvar frame = new JFrame( \"Keymaps Demo\" );\nvar panel = new MainPanel();\nframe.add( panel );\nframe.setPreferredSize( new Dimension( 200, 100 ) );\nframe.pack();\nframe.setVisible( true );\n\n\n\n\n\nMainPanel showing text “hello”\n\n\n\n\nCode\n/*\n#| include: false\n*/\nimport javax.swing.JComponent;\nimport javax.swing.SwingUtilities;\n\n\nTo set up ui-behaviour for the panel, we first need an instance of InputActionBindings\n\n\nCode\nimport org.scijava.ui.behaviour.util.InputActionBindings;\n\nvar bindings = new InputActionBindings();\n\n\nInputActionBindings bind inputs to actions.\nThis is of course exactly what AWT/Swing’s Key Bindings framework (InputMap, ActionMap) does. InputActionBindings adds very little over that; basically only more convenient InputMap chaining.\nSide note: The initial purpose of ui-behaviour was to offer a similar framework for mouse clicks, scrolls, drags, etc. Modeled after InputMap and ActionMap, there are InputTriggerMap and BehaviourMap. Analogous to InputActionBindings there is TriggerBehaviourBindings.\nAnyway, we connect the InputActionBindings instance to our MainPanel as follows.\n\n\nCode\nSwingUtilities.replaceUIActionMap(\n    panel,\n    bindings.getConcatenatedActionMap() );\nSwingUtilities.replaceUIInputMap(\n    panel, JComponent.WHEN_ANCESTOR_OF_FOCUSED_COMPONENT,\n    bindings.getConcatenatedInputMap() );\n\n\nInputActionBindings manages a chain of InputMap/ActionMap pairs. An Actions object encapsulates one such pair, and feeds new action definitions into it. We create a new Actions (the constructor arguments don’t matter for now) …\n\n\nCode\nimport org.scijava.ui.behaviour.io.InputTriggerConfig;\nimport org.scijava.ui.behaviour.util.Actions;\n\nvar actions = new Actions( new InputTriggerConfig(), \"demo\" );\n\n\n… and we add the pair to our InputActionBindings under the name “actions”.\n\n\nCode\nactions.install( bindings, \"actions\" );\n\n\n(We could use the name later to remove, replace, or temporarily block the InputMap/ActionMap pair.)\nThe actions instance is now connected to the panel via bindings. We can finally use it to add new shortcuts.\n\n\nCode\nactions.runnableAction(\n    () -&gt; panel.setText( \"Action A triggered\" ),\n    \"Action A\",\n    \"SPACE\", \"A\" );\n\n\nThe actions.runnableAction method takes the following arguments\npublic void runnableAction(\n    final Runnable runnable,\n    final String name,\n    final String... defaultKeyStrokes )\n\nA Runnable to run when the action is triggered.\nA unique name for the action (this will be used as the actions key in the underlying InputMap/ActionMap.\nZero or more keystrokes that should trigger the action.\n\nHere for example, the Runnable sets the text “Action A triggered” in the panel label. It is added under the name “Action A”, and triggered by the “SPACE” key, or the “A” key by default. The syntax for key strokes is described here.\nLet’s add a few more actions.\n\n\nCode\nactions.runnableAction(\n    () -&gt; panel.setText( \"Action B triggered\" ),\n    \"Action B\",\n    \"B\", \"shift B\" );\nactions.runnableAction(\n    () -&gt; panel.setText( \"Action C triggered\" ),\n    \"Action C\",\n    \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\" );\n\n\nNow we can use these defined shortcuts to run these three actions (which will change the text label to “Action A/B/C triggered”.\n  You can find the full example on github."
  },
  {
    "objectID": "posts/2022-08-08-keymaps/2022-08-08-keymaps.html#making-shortcuts-configurable",
    "href": "posts/2022-08-08-keymaps/2022-08-08-keymaps.html#making-shortcuts-configurable",
    "title": "User-configurable Keymaps",
    "section": "Making shortcuts configurable",
    "text": "Making shortcuts configurable\nAnother goal of ui-behaviour is to make mouse and key bindings easily configurable by the user (for example through config files).\nThis is the purpose of the Actions constructor arguments\nvar action = new Actions( new InputTriggerConfig(), \"demo\" );\nThe first argument is a InputTriggerConfig, and after that one or more String contexts are given (more on that later).\nThe InputTriggerConfig contains is basically a map from action names to key bindings. When adding a new action, for example like this:\nactions.runnableAction(\n    () -&gt; mainPanel.setText( \"Action B triggered\" ),\n    \"Action B\",\n    \"B\", \"shift B\" );\nthen actions will first look into its InputTriggerConfig to check whether any key binding is associated with the respective action name (“Action B”). If nothing is defined in the InputTriggerConfig then (and only then) the specified default key bindings will be used (\"B\" and \"shift B\").\n\nLoading shortcuts from a config file\nSo far, we just used a new, empty InputTriggerConfig, meaning we just get the specified defaults, which is exactly what we want for prototyping. If the project becomes more mature, and we want to change the config from outside, we can load the InputTriggerConfig from a config file.\n\n\nCode\nimport org.scijava.ui.behaviour.io.yaml.YamlConfigIO;\n\nReader reader = new FileReader( \"config.yaml\" );\nvar config = new InputTriggerConfig( YamlConfigIO.read( reader ) );\n\n\nThe config.yaml file looks like this:\n---\n- !mapping\naction: Action A\ncontexts: [demo]\ntriggers: [SPACE, A]\n- !mapping\naction: Action B\ncontexts: [demo]\ntriggers: [N]\nThe format should be more or less self-explanatory.\nThe loaded config should now map the String \"Action A\" to the Set of Strings {\"SPACE\", \"A\"}, and \"Action B\" to {\"N\"}. We could set up actions with the loaded config in the constructor, and then define the same actions as in the previous example.\nAlternatively, we can just update the existing Actions with the new config.\n\n\nCode\nactions.updateKeyConfig(config, false);\n\n\nThe config contains bindings for “Action A” and “Action B”. These will override the specified default bindings. So “Action A” will be triggered by the “SPACE” or “A” keys, and “Action B” will be triggered by “N”.\nThe config doesn’t specify anything for “Action C”, so that will be triggered by the programmatically specified defaults, that is, “1”, “2”, etc.\n\n\nAction context\nBesides the InputTriggerConfig, the Actions constructor also requires one ore more String... context arguments.\nThe idea is that the same action (or at least action name) might occur in different contexts, that is, different tools, different windows of the same tool, etc. For example, an action named “Undo” could occur in many contexts and it would be nice to be able to assign different shortcuts, depending on context.\nTherefore, an InputTriggerConfig does not directly map action to shortcuts, but rather maps (action, context) pairs to shortcuts, where action and context are both Strings. So, for example, (\"Undo\", \"bdv\") can map to a different shortcut than (\"Undo\", \"paintera\").\nThe context arguments given in the Actions constructor specify which subsets of key bindings defined in the InputTriggerConfig should be considered. In the above example, we have\nvar actions = new Actions( config, \"demo\" )\nThis actions will pick up bindings for (\"Undo\", \"demo\") from the config, but not (\"Undo\", \"bdv\") for example.\n\n\nDisabled actions\nThere is a special trigger \"not mapped\" that can be used to specify that a particular action should not be associated to any shortcut. For example, if we add\n- !mapping\naction: Action C\ncontexts: [demo]\ntriggers: [not mapped]\nto the config.yaml file, then “Action C” will be disabled, that is, the programmatic defaults “1”, “2”, etc., will not be used.\nYou can find the full example on github."
  },
  {
    "objectID": "posts/2022-08-08-keymaps/2022-08-08-keymaps.html#configuring-shortcuts-through-the-ui",
    "href": "posts/2022-08-08-keymaps/2022-08-08-keymaps.html#configuring-shortcuts-through-the-ui",
    "title": "User-configurable Keymaps",
    "section": "Configuring shortcuts through the UI",
    "text": "Configuring shortcuts through the UI\nBeing able to define shortcuts through a config file is useful. The config files can be edited, and distributed between different users or computers.\nEven more comfortable is to be able to modify shortcuts directly through the UI, at runtime.\n\nPreferences dialog\nFor this, we use bdv.ui.settings.SettingsPanel. This panel implements a typical Preferences layout (like it’s used in Eclipse, for example) with a tree of preferences sections on the left, the selected section on the right, and Apply, Ok, Cancel buttons on the bottom.\nThe following PrefererencesDialog contains only the SettingsPanel, and a method addPage() to adds new sections (bdv.ui.settings.SettingsPage) to the preferences tree.\n\n\nCode\n/*\n#| include: false\n*/\nimport java.awt.Frame;\nimport java.awt.event.WindowAdapter;\nimport java.awt.event.WindowEvent;\n\nimport javax.swing.JDialog;\nimport javax.swing.WindowConstants;\n\n\n\n\nCode\nimport bdv.ui.settings.SettingsPage;\nimport bdv.ui.settings.SettingsPanel;\n\npublic class PreferencesDialog extends JDialog\n{\n    private final SettingsPanel settingsPanel;\n\n    public PreferencesDialog( final Frame owner )\n    {\n        super( owner, \"Preferences\", false );\n        settingsPanel = new SettingsPanel();\n        settingsPanel.onOk( () -&gt; setVisible( false ) );\n        settingsPanel.onCancel( () -&gt; setVisible( false ) );\n\n        setDefaultCloseOperation( WindowConstants.HIDE_ON_CLOSE );\n        addWindowListener( new WindowAdapter()\n        {\n            @Override\n            public void windowClosing( final WindowEvent e )\n            {\n                settingsPanel.cancel();\n            }\n        } );\n\n        getContentPane().add( settingsPanel, BorderLayout.CENTER );\n        pack();\n    }\n\n    public void addPage( final SettingsPage page )\n    {\n        settingsPanel.addPage( page );\n        pack();\n    }\n}\n\n\nLet’s instantiate a PreferencesDialog for our example, and add a keyboard shortcut (command-comma or control-comma) to show it.\n\n\nCode\nvar preferencesDialog = new PreferencesDialog( frame );\nactions.runnableAction(\n    () -&gt; preferencesDialog.setVisible( !preferencesDialog.isVisible() ),\n    \"Preferences\",\n    \"meta COMMA\", \"ctrl COMMA\" );\n\n\nNext, we want to add a preferences section for configuring shortcuts. There is bdv.ui.keymap.KeymapSettingsPage that we can readily use. In the end this will give us something like this:  What remains to be done is to fill the settings page with a list of configurable actions.\n\n\nCommandDescriptions\nSpecifially, we need to supply the KeymapSettingsPage with a list of existing actions, with short textual descriptions. This is done by creating a CommandDescriptions object and adding the configurable actions.\n\n\nCode\nimport org.scijava.ui.behaviour.io.gui.CommandDescriptions;\n\nvar descriptions = new CommandDescriptions();\n\ndescriptions.setKeyconfigContext( \"demo\" );\n\ndescriptions.add( \"Action A\", new String[] { \"SPACE\" }, \"trigger Action A\" );\ndescriptions.add( \"Action B\", new String[] { \"B\", \"shift B\" }, \"trigger Action B\" );\n\n\nFor each action, we add its name and default shortcuts in the same way we did when creating the action, and a short description (this is just for showing to the user, so can be left empty if you’re lazy…).\nThe other thing we need to supply to the KeymapSettingsPage is a KeymapManager. KeymapManager maintains a set of named Keymaps (some built-in, some user-defined). A Keymap is a simple container for a InputTriggerConfig, adding just a name and support for listeners to be notified when the InputTriggerConfig changes.\nOur KeymapManager extends the existing AbstractKeymapManager base class. The only thing that needs to be done is providing one or more default Keymaps. We can build a default keymap from the above descriptions. (But they could also be loaded from resources, build manually, …)\n\n\nCode\nimport bdv.ui.keymap.AbstractKeymapManager;\nimport bdv.ui.keymap.Keymap;\n\nvar defaultKeymap = new Keymap( \"Default\", descriptions.createDefaultKeyconfig() );\n\n/**\n * Manages a collection of {@link Keymap}.\n */\npublic class KeymapManager extends AbstractKeymapManager&lt; KeymapManager &gt;\n{\n    @Override\n    protected List&lt; Keymap &gt; loadBuiltinStyles()\n    {\n        return Collections.singletonList( defaultKeymap );\n    }\n\n    @Override\n    public void saveStyles()\n    {\n        // not implemented.\n        // Here we would save user defined keymaps to YAML files, for example.\n    }\n}\n\n\nWe create a KeyMapManager instance and add it to the Preferences dialog (via KeymapSettingsPage).\n\n\nCode\nimport bdv.ui.keymap.KeymapSettingsPage;\n\nvar keymapManager = new KeymapManager();\npreferencesDialog.addPage(\n        new KeymapSettingsPage( \"Keymap\", keymapManager, new KeymapManager(), descriptions ) );\n\n\nThe KeyMapManager (via its base class) exposes the user-selected keymap. We set that for our actions object. We also add a listener that refreshes actions keybinding when that keymap changes.\n\n\nCode\nvar keymap = keymapManager.getForwardSelectedKeymap();\nactions.updateKeyConfig( keymap.getConfig(), false );\nkeymap.updateListeners().add(\n    () -&gt; actions.updateKeyConfig( keymap.getConfig(), false )\n);\n\n\ntrue\n\n\nThat’s it. The user can now use the Preferences dialog to define custom keymaps with shortcuts to their liking, and switch between different keymaps. (Use command-comma or control-comma to show the preferences dialog).\nYou can find the full example on github."
  },
  {
    "objectID": "posts/2022-08-08-keymaps/2022-08-08-keymaps.html#making-action-descriptions-discoverable",
    "href": "posts/2022-08-08-keymaps/2022-08-08-keymaps.html#making-action-descriptions-discoverable",
    "title": "User-configurable Keymaps",
    "section": "Making action descriptions discoverable",
    "text": "Making action descriptions discoverable\nKeeping the list of existing actions (that is, the CommandDescriptions) up to date is tedious. Actions that should appear in the config dialog may be scattered through your own code and dependencies. This can be somewhat automated with CommandDescriptionProviders. These are scijava @Plugins that can be discovered at runtime.\n\n\nCode\nimport org.scijava.plugin.Plugin;\nimport org.scijava.ui.behaviour.io.gui.CommandDescriptionProvider;\n\nvar DEMO_SCOPE = new CommandDescriptionProvider.Scope( \"tpietzsch.keymap\" );\nvar DEMO_CONTEXT = \"demo\";\n\n/*\n * Command descriptions for all provided commands\n */\n@Plugin( type = CommandDescriptionProvider.class )\npublic static class MyActionDescriptions extends CommandDescriptionProvider\n{\n    public MyActionDescriptions()\n    {\n        super( DEMO_SCOPE, DEMO_CONTEXT );\n    }\n\n    @Override\n    public void getCommandDescriptions( final CommandDescriptions descriptions )\n    {\n        descriptions.add( \"Action A\", new String[] { \"SPACE\" }, \"trigger Action A\" );\n        descriptions.add( \"Action B\", new String[] { \"B\", \"shift B\" }, \"trigger Action B\" );\n    }\n}\n\n\nFor discovery, we use a CommandDescriptionsBuilder\n\n\nCode\nimport org.scijava.Context;\nimport org.scijava.plugin.PluginService;\nimport org.scijava.ui.behaviour.io.gui.CommandDescriptionsBuilder;\n\nvar context = new Context( PluginService.class );\nvar builder = new CommandDescriptionsBuilder();\ncontext.inject( builder );\n\nbuilder.discoverProviders( DEMO_SCOPE );\n\n\nNote the use of DEMO_SCOPE here. The same scope is also given in the MyActionDescriptions constructor. The discoverProviders() method takes an optional scope argument, and will only discover CommandDescriptionProvider that match this scope. If no scope is given, all CommandDescriptionProvider on the classpath will be discovered. For example within Fiji, that would include actions from Mastodon and BigDataViewer.\nUnfortunately, the @Plugin annotations do not work for classes defined in JShell (used by this notebook). As a workaround, we can add MyActionDescriptions manually.\n\n\nCode\nbuilder.addManually( new MyActionDescriptions(), DEMO_CONTEXT );\n\n\nAfter we add everything we need to the builder, we can get the Descriptions.\n\n\nCode\nvar descriptions = builder.build();\n\n\nYou can find the full example on github."
  },
  {
    "objectID": "posts/2022-08-08-keymaps/2022-08-08-keymaps.html#recommended-pattern-for-defining-actions",
    "href": "posts/2022-08-08-keymaps/2022-08-08-keymaps.html#recommended-pattern-for-defining-actions",
    "title": "User-configurable Keymaps",
    "section": "Recommended pattern for defining actions",
    "text": "Recommended pattern for defining actions\nAction definitions in BigDataViewer and Mastodon are organized in the following way.\nA set of related actions is collected into a MyActions (for example) class. Action names and default shortcuts are defined as public static final constants, because they are used both for defining the actions, and for creating action Descriptions.\nThe actions contained in MyActions are described in a public static inner class Descriptions extends CommandDescriptionProvider.\nIn the Descriptions constructor, we give a scope for the respective library / tool. Ideally, the scope should be defined public static somewhere so that is can easily used outside the component to discover its actions. For example, BigDataViewer uses this scope. If another tool (BigStitcher, BigWarp, etc.) wants to include BDV shortcuts into its customizable keymaps, they can be easily discovered like that.\n\n\nCode\nimport org.scijava.plugin.Plugin;\nimport org.scijava.ui.behaviour.io.gui.CommandDescriptionProvider;\n\nfinal var DEMO_SCOPE = new CommandDescriptionProvider.Scope( \"tpietzsch.keymap-idiom\" );\nfinal var DEMO_CONTEXT = \"demo\";\n\npublic class MyActions\n{\n    // define action name constants\n    public static final String ACTION_A = \"Action A\";\n    public static final String ACTION_B = \"Action B\";\n    public static final String PREFERENCES = \"Preferences\";\n\n    // define default shortcut constants\n    public static final String[] ACTION_A_KEYS = { \"SPACE\" };\n\n    public static final String[] ACTION_B_KEYS = { \"B\", \"shift B\" };\n    public static final String[] PREFERENCES_KEYS = { \"meta COMMA\", \"ctrl COMMA\" };\n\n\n    /*\n     * Command descriptions for all provided commands\n     */\n    @Plugin( type = CommandDescriptionProvider.class )\n    public static class Descriptions extends CommandDescriptionProvider\n    {\n        public Descriptions()\n        {\n            super( DEMO_SCOPE, DEMO_CONTEXT );\n        }\n\n        @Override\n        public void getCommandDescriptions( final CommandDescriptions descriptions )\n        {\n            descriptions.add( ACTION_A, ACTION_A_KEYS, \"trigger Action A\" );\n            descriptions.add( ACTION_B, ACTION_B_KEYS, \"trigger Action B\" );\n            descriptions.add( PREFERENCES, PREFERENCES_KEYS, \"Show the Preferences dialog.\" );\n        }\n    }\n\n    \n    /**\n     * Install into the specified {@link Actions}.\n     */\n    public static void install( final Actions actions, final MainPanel mainPanel, final PreferencesDialog preferencesDialog )\n    {\n        actions.runnableAction( () -&gt; mainPanel.setText( \"Action A triggered\" ),\n                ACTION_A, ACTION_A_KEYS );\n        actions.runnableAction( () -&gt; mainPanel.setText( \"Action B triggered\" ),\n                ACTION_B, ACTION_B_KEYS );\n        actions.runnableAction( () -&gt; preferencesDialog.setVisible( !preferencesDialog.isVisible() ),\n                PREFERENCES, PREFERENCES_KEYS );\n    }\n}\n\n\nMyActions contains one install method that installs all actions into a provided Actions argument. Ideally, MyActions is stateless, and install method is static.\nThe remaining arguments to install are whatever is needed to create the actions. In the example, the mainPanel is needed to create “Action A” and “Action B”, and the preferencesDialog is needed to create the action to show/hide it.\nSo, MyActions.install(...) is called to install into a provided Actions. Usually every frame/panel in the application should have an Actions instance, which is linked to the KeymapManager so that keymap updates propagate correctly.\nAnd that’s it… This is currently the recommended way to structure and bundle action definitions. You can find the full example on github.\nSee BigDataViewer’s NavigationActions as an example “in the wild”. For behaviours (mouse gestures, etc.) the structure is the same. See BigDataViewer’s TransformEventHandler2D for example."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ImgLib2 news and tutorials",
    "section": "",
    "text": "Position and displacement field transforms\n\n\n\n\n\n\nimglib2\n\n\ntransform\n\n\ndeformation\n\n\ndisplacement\n\n\n\nCreate and apply non-linear transformations with imglib2.\n\n\n\n\n\nFeb 14, 2024\n\n\nJohn Bogovic\n\n\n\n\n\n\n\n\n\n\n\n\nAdding Stream support to ImgLib2\n\n\n\n\n\n\nimglib2\n\n\nstream-api\n\n\njava\n\n\n\nExamples and performance discussion of Java Streams in ImgLib2\n\n\n\n\n\nOct 30, 2022\n\n\nTobias Pietzsch\n\n\n\n\n\n\n\n\n\n\n\n\nHow to work with the N5 API and ImgLib2?\n\n\n\n\n\n\nimglib2\n\n\nn5\n\n\nhdf5\n\n\nzarr\n\n\njupyter\n\n\nnotebook\n\n\n\nRead and write ImgLib2 data with the N5 API\n\n\n\n\n\nSep 27, 2022\n\n\nStephan Saalfeld\n\n\n\n\n\n\n\n\n\n\n\n\nHow to display ImgLib2 data in a notebook?\n\n\n\n\n\n\nimglib2\n\n\njupyter\n\n\nnotebook\n\n\n\nRender ImgLib2 data into notebook objects\n\n\n\n\n\nSep 14, 2022\n\n\nStephan Saalfeld\n\n\n\n\n\n\n\n\n\n\n\n\nUser-configurable Keymaps\n\n\n\n\n\n\nui-behaviour\n\n\nbigdataviewer\n\n\n\nHow to set up user-configurable keyboard shortcuts using ui-behaviour and BigDataViewer’s Preferences Dialog\n\n\n\n\n\nAug 8, 2022\n\n\nTobias Pietzsch\n\n\n\n\n\n\n\n\n\n\n\n\nSetup the IJava jupyter kernel\n\n\n\n\n\n\njupyter\n\n\nijava\n\n\njshell\n\n\njava\n\n\nkernel\n\n\n\nFollow these instructions to setup the IJava jupyter kernel by Spencer Park.\n\n\n\n\n\nJun 5, 2022\n\n\nStephan Saalfeld\n\n\n\n\n\n\n\n\n\n\n\n\nJuliaset Lambda\n\n\n\n\n\n\nimglib2\n\n\nlambda\n\n\nfractal\n\n\njuliaset\n\n\nbigdataviewer\n\n\n\nInteractively render the Juliaset as a lambda function in BigDataViewer\n\n\n\n\n\nMay 2, 2022\n\n\nStephan Saalfeld\n\n\n\n\n\n\nNo matching items"
  }
]